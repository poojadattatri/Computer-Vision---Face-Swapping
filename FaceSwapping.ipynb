{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Working_copy_of_Face_Swapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Face Swapping in Videos"
      ],
      "metadata": {
        "id": "zVYYhJIiqO7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Configuration and Setup"
      ],
      "metadata": {
        "id": "yANYPdrPqfxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Package Installation"
      ],
      "metadata": {
        "id": "7VeVe9iUqSo_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNtjp-Bsv20J"
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Libraries"
      ],
      "metadata": {
        "id": "rJrR768eqZ8t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moxa2XUCxy5S"
      },
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "from scipy.spatial import Delaunay\n",
        "import skvideo.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mounting Google Drive"
      ],
      "metadata": {
        "id": "G-9KxF_nqmjA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riT_6zGkya42",
        "outputId": "505e7ad4-83b1-45b0-e7b2-627e1c21ed42"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPB0UmVtyiTz"
      },
      "source": [
        "!cp -r '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/model' /content\n",
        "!cp -r '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/videos/src' /content\n",
        "!cp -r '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/faceBlendCommon.py' /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization of Global Variables"
      ],
      "metadata": {
        "id": "RYuEMtzxsOJe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo-9JHrI_9Yv"
      },
      "source": [
        "MODEL_PATH = '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/model/'\n",
        "PREDICTOR_PATH = MODEL_PATH + \"shape_predictor_68_face_landmarks.dat\"\n",
        "RESIZE_HEIGHT = 480\n",
        "NUM_FRAMES_FOR_FPS = 100\n",
        "SKIP_FRAMES = 1\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inter Eye Distance Calculation for Stabilization"
      ],
      "metadata": {
        "id": "bGje9OVEsTrL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeF8_XefAoLo"
      },
      "source": [
        "def interEyeDistance(predict):\n",
        "  leftEyeLeftCorner = (predict[36].x, predict[36].y)\n",
        "  rightEyeRightCorner = (predict[45].x, predict[45].y)\n",
        "  distance = cv2.norm(np.array(rightEyeRightCorner) - np.array(leftEyeLeftCorner))\n",
        "  distance = int(distance)\n",
        "  return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmeA5z-J_-EI"
      },
      "source": [
        "## Face and Facial Landmark Detection with Stabilization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy5ZyLh5V6iI"
      },
      "source": [
        "def stabilise(im):\n",
        "  points=[]\n",
        "  pointsPrev=[]\n",
        "  pointsDetectedCur=[]\n",
        "  pointsDetectedPrev=[]\n",
        "  all_stabilized_frames=[]\n",
        "\n",
        "  eyeDistanceNotCalculated = True\n",
        "  eyeDistance = 0\n",
        "  isFirstFrame = True\n",
        "  fps = 10\n",
        "  showStabilized = False\n",
        "  count =0\n",
        "\n",
        "  imDlib = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "  imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) # improve image contrast\n",
        "  imGray = clahe.apply(imGray)\n",
        "  imGrayPrev = imGray\n",
        "\n",
        "  height = im.shape[0]\n",
        "\n",
        "  IMAGE_RESIZE = float(height)/RESIZE_HEIGHT\n",
        "  imSmall = cv2.resize(im, None, fx=1.0/IMAGE_RESIZE, fy=1.0/IMAGE_RESIZE,interpolation = cv2.INTER_LINEAR)\n",
        "  imSmallDlib = cv2.cvtColor(imSmall, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  faces = detector(imSmallDlib,0)\n",
        "\n",
        "  if len(faces)==0:\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "    for i in range(0,len(faces)):\n",
        "        newRect = dlib.rectangle(int(faces[i].left() * IMAGE_RESIZE),\n",
        "          int(faces[i].top() * IMAGE_RESIZE),\n",
        "          int(faces[i].right() * IMAGE_RESIZE),\n",
        "          int(faces[i].bottom() * IMAGE_RESIZE))\n",
        "        \n",
        "        landmarks = landmarkDetector(imDlib, newRect).parts()\n",
        "\n",
        "        if (isFirstFrame==True):\n",
        "          pointsPrev=[]\n",
        "          pointsDetectedPrev = []\n",
        "          [pointsPrev.append((p.x, p.y)) for p in landmarks]\n",
        "          [pointsDetectedPrev.append((p.x, p.y)) for p in landmarks]\n",
        "        else:\n",
        "          pointsPrev=[]\n",
        "          pointsDetectedPrev = []\n",
        "          pointsPrev = points\n",
        "          pointsDetectedPrev = pointsDetectedCur\n",
        "\n",
        "        points = []\n",
        "        pointsDetectedCur = []\n",
        "        [points.append((p.x, p.y)) for p in landmarks]\n",
        "        [pointsDetectedCur.append((p.x, p.y)) for p in landmarks]\n",
        "        pointsArr = np.array(points,np.float32)\n",
        "        pointsPrevArr = np.array(pointsPrev,np.float32)\n",
        "\n",
        "        if eyeDistanceNotCalculated:\n",
        "          eyeDistance = interEyeDistance(landmarks)\n",
        "          eyeDistanceNotCalculated = False\n",
        "\n",
        "        if eyeDistance > 100:\n",
        "            dotRadius = 3\n",
        "        else:\n",
        "          dotRadius = 2\n",
        "\n",
        "        sigma = eyeDistance * eyeDistance / 400\n",
        "        s = 2*int(eyeDistance/4)+1\n",
        "        lk_params = dict(winSize  = (s, s), maxLevel = 5, criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 20, 0.03))\n",
        "        pointsArr,status, err = cv2.calcOpticalFlowPyrLK(imGrayPrev,imGray,pointsPrevArr,pointsArr,**lk_params)\n",
        "        pointsArrFloat = np.array(pointsArr,np.float32)\n",
        "        points = pointsArrFloat.tolist()\n",
        "\n",
        "        for k in range(0,len(landmarks)):\n",
        "          d = cv2.norm(np.array(pointsDetectedPrev[k]) - np.array(pointsDetectedCur[k]))\n",
        "          alpha = math.exp(-d*d/sigma)\n",
        "          points[k] = (1 - alpha) * np.array(pointsDetectedCur[k]) + alpha * np.array(points[k])\n",
        "    return points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convex Hull Creation"
      ],
      "metadata": {
        "id": "8yYDo9LdspNh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AsQO5VKi61u"
      },
      "source": [
        "def convex_hull(points, points1):\n",
        "  vec = np.empty([68,2], dtype=int)\n",
        "  for b in range(68):\n",
        "    vec[b][0] = points[b][0]\n",
        "    vec[b][1] = points[b][1]\n",
        "\n",
        "  indices = cv2.convexHull(np.array(vec), returnPoints = False)\n",
        "  hull1 = vec[indices[:,0]]\n",
        "  vec1 = np.empty([68,2], dtype=int)\n",
        "  for b in range(68):\n",
        "    vec1[b][0] = points1[b][0]\n",
        "    vec1[b][1] = points1[b][1]\n",
        "  hull2 = vec1[indices[:,0]]\n",
        "  return hull1, hull2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warping and Affine Tranformation"
      ],
      "metadata": {
        "id": "hOY9S3eBsv3V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJOp3ae7bJFj"
      },
      "source": [
        "def warpTriangle(img1, img2, tri1, tri2):\n",
        "    rect1 = cv2.boundingRect(np.float32([tri1]))\n",
        "    rect2 = cv2.boundingRect(np.float32([tri2]))\n",
        "\n",
        "    tri1Rect = np.zeros((3,2))\n",
        "    tri2Rect = np.zeros((3,2))\n",
        "\n",
        "    for i in range(0, 3):\n",
        "        tri1Rect[i] = ((tri1[i][0] - rect1[0]), (tri1[i][1] - rect1[1]))\n",
        "        tri2Rect[i] = (((tri2[i][0] - rect2[0]), (tri2[i][1] - rect2[1])))\n",
        "\n",
        "    mask = np.zeros((rect2[3], rect2[2], 3), dtype=np.float32)\n",
        "    cv2.fillConvexPoly(mask, np.int32(tri2Rect), (1.0, 1.0, 1.0), 16, 0);\n",
        "\n",
        "    img1Rect = img1[rect1[1]:rect1[1] + rect1[3], rect1[0]:rect1[0] + rect1[2]]\n",
        "\n",
        "    size = (rect2[2], rect2[3])\n",
        "\n",
        "    affineWarped = cv2.getAffineTransform(np.float32(tri1Rect), np.float32(tri2Rect))\n",
        "    img2Rect = cv2.warpAffine(img1Rect, affineWarped, (size[0], size[1]), None, flags=cv2.INTER_LINEAR,borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    img2Rect = img2Rect * mask\n",
        "\n",
        "    img2[rect2[1]:rect2[1] + rect2[3], rect2[0]:rect2[0] + rect2[2]] = img2[rect2[1]:rect2[1] + rect2[3], rect2[0]:rect2[0] + rect2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
        "    img2[rect2[1]:rect2[1] + rect2[3], rect2[0]:rect2[0] + rect2[2]] = img2[rect2[1]:rect2[1] + rect2[3], rect2[0]:rect2[0] + rect2[2]] + img2Rect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delaunay Triangulation"
      ],
      "metadata": {
        "id": "ve9KW1iXs8ph"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJP_lkrsalXF"
      },
      "source": [
        "def triangulation(hull1, hull2, img1, img1Warped):\n",
        "\n",
        "  img2 = np.copy(img1Warped)\n",
        "\n",
        "  tri = Delaunay(hull2).simplices\n",
        "\n",
        "  numTriangles = len(tri)\n",
        "  for i in range(0, numTriangles):\n",
        "    triangle = tri[i]\n",
        "    pts1 = np.zeros((3, 2), dtype=np.float32)\n",
        "    pts2 = np.zeros((3, 2), dtype=np.float32)\n",
        "\n",
        "    pts1[0] = hull1[triangle[0]]\n",
        "    pts1[1] = hull1[triangle[1]]\n",
        "    pts1[2] = hull1[triangle[2]]\n",
        "\n",
        "    pts2[0] = hull2[triangle[0]]\n",
        "    pts2[1] = hull2[triangle[1]]\n",
        "    pts2[2] = hull2[triangle[2]]\n",
        "\n",
        "    warpTriangle(img1, img1Warped, pts1, pts2)\n",
        "\n",
        "  mask = np.zeros(img1.shape, dtype=img1.dtype)\n",
        "  cv2.fillConvexPoly(mask, np.int32(hull2), (255, 255, 255))\n",
        "\n",
        "  r = cv2.boundingRect(np.float32([hull2]))\n",
        "  faceCenter = (r[0]+int(r[2]/2), r[1]+int(r[3]/2))\n",
        "\n",
        "  finalImage = cv2.seamlessClone(np.uint8(img1Warped), np.uint8(img2), mask, faceCenter, cv2.NORMAL_CLONE)\n",
        "\n",
        "  return cv2.cvtColor(np.uint8(finalImage), cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Reading and Initiation of the Face Swapping Procedure"
      ],
      "metadata": {
        "id": "bJflP8zQtC7e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DkxI4ZcWeXt"
      },
      "source": [
        "video_path = '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/videos/src/FrankUnderwood.mp4'\n",
        "video_name = video_path.split(\"/\")[-1].split(\".\")[0]\n",
        "cap= cv2.VideoCapture(video_path)\n",
        "pic, frame = cap.read()\n",
        "pic=True\n",
        "frames1 = []\n",
        "while(pic):\n",
        "    pic, frame = cap.read()\n",
        "    if pic==True:\n",
        "        frames1.append(frame)\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "\n",
        "video_path = '/content/gdrive/Shareddrives/CIS 581- Face Swapping In Videos/project/videos/target/FrankUnderwood- target.mp4'\n",
        "video_name = video_path.split(\"/\")[-1].split(\".\")[0]\n",
        "cap= cv2.VideoCapture(video_path)\n",
        "pic, frame = cap.read()\n",
        "pic=True\n",
        "frames2=[]\n",
        "while(pic):\n",
        "    pic, frame = cap.read()\n",
        "    if pic==True:\n",
        "        frames2.append(frame)\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "\n",
        "plt.imshow(frames1[5][:,:,::-1])\n",
        "\n",
        "[h1, w1, _] = frames1[0].shape\n",
        "swappedVid1 = np.zeros((len(frames1) - 1, h1, w1, 3), dtype=np.uint8)\n",
        "\n",
        "for i in range(len(frames1) - 1):\n",
        "    if i < len(frames2) - 1: \n",
        "        img1 = frames2[i]\n",
        "    else:\n",
        "        img1 = frames2[len(frames2) - 2]\n",
        "    points=stabilise(img1)\n",
        "    points1=stabilise(frames1[i])\n",
        "    if(points is None or points1 is None):\n",
        "      continue\n",
        "    hull1,hull2=convex_hull(points,points1)\n",
        "    img2=np.copy(frames1[i])\n",
        "    swappedVid1[i,:,:,:] = triangulation(hull1,hull2, img1, img2 )\n",
        "    \n",
        "\n",
        "[h2, w2, _] = frames2[0].shape\n",
        "swappedVid2 = np.zeros((len(frames2) - 1, h2, w2, 3), dtype=np.uint8)\n",
        "\n",
        "for j in range(len(frames2) - 1):\n",
        "    if j < len(frames1) - 1: \n",
        "        img1 = frames1[j]\n",
        "    else:\n",
        "        img1 = frames1[len(frames1) - 2]\n",
        "    points=stabilise(img1)\n",
        "    points1=stabilise(frames2[j])\n",
        "    if(points is None or points1 is None):\n",
        "      continue\n",
        "    hull1,hull2=convex_hull(points,points1)\n",
        "    img2=np.copy(frames2[j])\n",
        "\n",
        "    swappedVid2[j,:,:,:] = triangulation(hull1,hull2, img1, img2)\n",
        "   \n",
        "\n",
        "skvideo.io.vwrite(\"face2_on_video1.mp4\", swappedVid1)\n",
        "skvideo.io.vwrite(\"face1_on_video2.mp4\", swappedVid2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}